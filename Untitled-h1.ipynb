{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5099909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Zapisano surowy HTML do debug_page_1.html\n",
      "INFO:__main__:Strona 1: znaleziono 13 linków. Przykłady: ['https://www.otomoto.pl/osobowe/oferta/volkswagen-passat-ID6HJ8X0.html', 'https://www.otomoto.pl/osobowe/oferta/volkswagen-passat-ID6HGQO5.html', 'https://www.otomoto.pl/osobowe/oferta/volkswagen-passat-ID6HKcpM.html']\n",
      "INFO:__main__:Strona 1: znaleziono 13 linków. Przykłady: ['https://www.otomoto.pl/osobowe/oferta/volkswagen-passat-ID6HJ8X0.html', 'https://www.otomoto.pl/osobowe/oferta/volkswagen-passat-ID6HGQO5.html', 'https://www.otomoto.pl/osobowe/oferta/volkswagen-passat-ID6HKcpM.html']\n",
      "INFO:__main__:Zapisano surowy HTML do debug_page_2.html\n",
      "INFO:__main__:Zapisano surowy HTML do debug_page_2.html\n",
      "INFO:__main__:Strona 2: znaleziono 0 linków. Przykłady: []\n",
      "INFO:__main__:Strona 2: znaleziono 0 linków. Przykłady: []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'passat_B5FL_otomoto.csv'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install requests beautifulsoup4 python-dateutil\n",
    "import csv, json, re, time, logging\n",
    "from urllib.parse import urlparse, parse_qs, urlencode, urlunparse, urljoin\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil.parser import parse as dtparse\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "# single-string User-Agent header\n",
    "UA = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0 Safari/537.36\"}\n",
    "\n",
    "# Reuse a session for connection pooling and consistent headers\n",
    "SESSION = requests.Session()\n",
    "SESSION.headers.update(UA)\n",
    "\n",
    "\n",
    "def with_page(url, page):\n",
    "    u = urlparse(url)\n",
    "    q = parse_qs(u.query)\n",
    "    q[\"page\"] = [str(page)]\n",
    "    new_q = urlencode(q, doseq=True)\n",
    "    return urlunparse((u.scheme, u.netloc, u.path, u.params, new_q, u.fragment))\n",
    "\n",
    "\n",
    "def listing_links_from_results(html, base_url):\n",
    "    \"\"\"\n",
    "    Zwraca listę absolutnych URL-i do kart ogłoszeń znalezionych w html.\n",
    "    Obsługuje relatywne href-y (zamienia na absolutne) i prostą heurystykę\n",
    "    dla otomoto/olx (rozszerzalne).\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    hrefs = [a.get(\"href\") for a in soup.find_all(\"a\", href=True)]\n",
    "    # usuń None i zrób absolutne adresy\n",
    "    abs_hrefs = [urljoin(base_url, h) for h in hrefs if h]\n",
    "\n",
    "    # proste wzorce (dodaj kolejne w razie potrzeby)\n",
    "    patterns = [\n",
    "        re.compile(r\"https?://[^/]*otomoto\\.pl/.+?/oferta/.+?ID[A-Za-z0-9]+\\.html\"),\n",
    "        re.compile(r\"https?://[^/]*olx\\.pl/.+?/oferta/.+?-\\d+\"),  # przykładowy wzorzec OLX\n",
    "        re.compile(r\"/oferta/\"),  # fallback: zawiera '/oferta/'\n",
    "    ]\n",
    "    matches = []\n",
    "    for h in abs_hrefs:\n",
    "        for p in patterns:\n",
    "            try:\n",
    "                if p.search(h):\n",
    "                    matches.append(h)\n",
    "                    break\n",
    "            except Exception:\n",
    "                continue\n",
    "    # deduplikuj, zachowując porządek\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for u in matches:\n",
    "        if u not in seen:\n",
    "            seen.add(u)\n",
    "            result.append(u)\n",
    "    return result\n",
    "\n",
    "\n",
    "def extract_from_jsonld(soup):\n",
    "    # Szukamy <script type=\"application/ld+json\"> i wyciągamy najważniejsze pola\n",
    "    items = []\n",
    "    for tag in soup.find_all(\"script\", type=\"application/ld+json\"):\n",
    "        txt = tag.string\n",
    "        # tag.string bywa None - pomijamy w takiej sytuacji\n",
    "        if not txt or not isinstance(txt, str):\n",
    "            continue\n",
    "        try:\n",
    "            data = json.loads(txt.strip())\n",
    "        except Exception:\n",
    "            # czasem zawiera javascript-owy wrapper lub pojedyncze obiekty — pomiń\n",
    "            continue\n",
    "        if isinstance(data, dict):\n",
    "            items.append(data)\n",
    "        elif isinstance(data, list):\n",
    "            items += [d for d in data if isinstance(d, dict)]\n",
    "    # heurystyka\n",
    "    best = {}\n",
    "    for d in items:\n",
    "        ctx = d.get(\"@context\", \"\") or \"\"\n",
    "        typ = d.get(\"@type\", \"\") or \"\"\n",
    "        if \"schema.org\" in ctx and (typ in (\"Product\", \"Vehicle\", \"Offer\", \"Car\")):\n",
    "            best = d\n",
    "            break\n",
    "    return best\n",
    "\n",
    "\n",
    "def scrape_detail(url):\n",
    "    try:\n",
    "        r = SESSION.get(url, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        j = extract_from_jsonld(soup) or {}\n",
    "\n",
    "        # fallbacky — jeśli JSON-LD nie zawiera podstawowych pól, próbujemy z HTML\n",
    "        def pick(*keys, default=\"\"):\n",
    "            for k in keys:\n",
    "                if k in j:\n",
    "                    return j[k]\n",
    "            return default\n",
    "\n",
    "        name = pick(\"name\", \"headline\")\n",
    "        if not name:\n",
    "            # spróbuj tytułu z HTML\n",
    "            h1 = soup.find(\"h1\")\n",
    "            name = (h1.get_text(strip=True) if h1 else (soup.title.string.strip() if soup.title and soup.title.string else \"\"))\n",
    "\n",
    "        brand = j.get(\"brand\") if isinstance(j.get(\"brand\"), str) else (j.get(\"brand\", {}).get(\"name\") if isinstance(j.get(\"brand\"), dict) else \"\")\n",
    "        model = j.get(\"model\", \"\") or j.get(\"vehicleModel\", \"\")\n",
    "\n",
    "        offers = j.get(\"offers\") or {}\n",
    "        price = \"\"\n",
    "        currency = \"\"\n",
    "        if isinstance(offers, dict):\n",
    "            price = offers.get(\"price\", \"\") or offers.get(\"priceSpecification\", {}).get(\"price\", \"\")\n",
    "            currency = offers.get(\"priceCurrency\", \"\") or offers.get(\"priceSpecification\", {}).get(\"priceCurrency\", \"\")\n",
    "        # dodatkowy fallback dla metadanych\n",
    "        if not price:\n",
    "            meta_price = soup.find(\"meta\", attrs={\"property\": \"product:price:amount\"}) or soup.find(\"meta\", attrs={\"name\": \"price\"})\n",
    "            if meta_price and meta_price.get(\"content\"):\n",
    "                price = meta_price.get(\"content\")\n",
    "\n",
    "        year = j.get(\"productionDate\", \"\") or j.get(\"modelDate\", \"\")\n",
    "        if year:\n",
    "            try:\n",
    "                year = str(dtparse(str(year)).year)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        mileage = j.get(\"mileageFrom\", \"\") or j.get(\"mileage\", \"\") or \"\"\n",
    "\n",
    "        return {\n",
    "            \"url\": url,\n",
    "            \"title\": name,\n",
    "            \"brand\": brand or \"\",\n",
    "            \"model\": model or \"\",\n",
    "            \"year\": year,\n",
    "            \"mileage\": mileage,\n",
    "            \"price\": price or \"\",\n",
    "            \"currency\": currency or \"\",\n",
    "        }\n",
    "    except Exception as e:\n",
    "        log.exception(\"Błąd przy pobieraniu szczegółów: %s\", url)\n",
    "        # Zwracamy przynajmniej URL i informację o błędzie\n",
    "        return {\"url\": url, \"title\": \"\", \"brand\": \"\", \"model\": \"\", \"year\": \"\", \"mileage\": \"\", \"price\": \"\", \"currency\": \"\", \"error\": str(e)}\n",
    "\n",
    "\n",
    "def scrape_search(search_url, pages=2, delay=2.0, out_csv=\"otomoto_export.csv\", debug=False):\n",
    "    seen = set()\n",
    "    details = []\n",
    "    for p in range(1, pages + 1):\n",
    "        url = with_page(search_url, p)\n",
    "        try:\n",
    "            rr = SESSION.get(url, timeout=30)\n",
    "            if rr.status_code != 200:\n",
    "                log.warning(\"Strona %s zwróciła status %s\", url, rr.status_code)\n",
    "                break\n",
    "        except Exception as e:\n",
    "            log.exception(\"Błąd przy pobieraniu strony wyników: %s\", url)\n",
    "            break\n",
    "\n",
    "        if debug:\n",
    "            # zapisz surowy HTML, ułatwia debugowanie selektorów\n",
    "            fname = f\"debug_page_{p}.html\"\n",
    "            with open(fname, \"w\", encoding=\"utf-8\") as fh:\n",
    "                fh.write(rr.text)\n",
    "            log.info(\"Zapisano surowy HTML do %s\", fname)\n",
    "\n",
    "        links = listing_links_from_results(rr.text, url)\n",
    "        log.info(\"Strona %s: znaleziono %d linków. Przykłady: %s\", p, len(links), links[:3])\n",
    "\n",
    "        for link in links:\n",
    "            if link in seen:\n",
    "                continue\n",
    "            seen.add(link)\n",
    "            details.append(scrape_detail(link))\n",
    "            time.sleep(delay)  # bądź kulturalny dla serwisu\n",
    "\n",
    "    # Zapis do CSV\n",
    "    cols = [\"url\", \"title\", \"brand\", \"model\", \"year\", \"mileage\", \"price\", \"currency\"]\n",
    "    with open(out_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=cols)\n",
    "        w.writeheader()\n",
    "        for row in details:\n",
    "            # upewnij się, że wszystkie kolumny istnieją\n",
    "            out_row = {k: row.get(k, \"\") for k in cols}\n",
    "            w.writerow(out_row)\n",
    "    return out_csv\n",
    "\n",
    "# PRZYKŁAD (użyj podanego przez Ciebie URL):\n",
    "search = \"https://www.otomoto.pl/osobowe/volkswagen/passat/seg-sedan?search%5Bfilter_enum_fuel_type%5D=diesel&search%5Bfilter_enum_generation%5D=gen-b5-fl-2000-2005&search%5Badvanced_search_expanded%5D=true\"\n",
    "# Uruchom w swoim środowisku, np.:\n",
    "scrape_search(search, pages=2, delay=1.5, out_csv=\"passat_B5FL_otomoto.csv\", debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e543c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing: ['requests', 'beautifulsoup4', 'python-dateutil'] into c:\\Python314\\python.exe\n",
      "Verifying imports:\n",
      "  requests: OK, version=2.32.5\n",
      "  bs4: OK, version=4.14.2\n",
      "  dateutil: OK, version=2.9.0.post0\n",
      "If this cell ran without import errors, restart the notebook kernel and re-open the file to clear Pylance/VSCode diagnostics.\n",
      "Verifying imports:\n",
      "  requests: OK, version=2.32.5\n",
      "  bs4: OK, version=4.14.2\n",
      "  dateutil: OK, version=2.9.0.post0\n",
      "If this cell ran without import errors, restart the notebook kernel and re-open the file to clear Pylance/VSCode diagnostics.\n"
     ]
    }
   ],
   "source": [
    "# Quick environment setup: run this cell once to install packages in the notebook's Python environment.\n",
    "# It uses the same Python that's running this notebook (sys.executable).\n",
    "import sys, subprocess, importlib\n",
    "packages = [\"requests\", \"beautifulsoup4\", \"python-dateutil\"]\n",
    "print(f\"Installing: {packages} into {sys.executable}\")\n",
    "try:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\"] + packages)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"pip install failed:\", e)\n",
    "    raise\n",
    "\n",
    "print(\"Verifying imports:\")\n",
    "for pkg in (\"requests\", \"bs4\", \"dateutil\"):\n",
    "    try:\n",
    "        m = importlib.import_module(pkg)\n",
    "        ver = getattr(m, \"__version__\", getattr(m, \"VERSION\", \"unknown\"))\n",
    "        print(f\"  {pkg}: OK, version={ver}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  {pkg}: FAILED -> {e}\")\n",
    "\n",
    "print(\"If this cell ran without import errors, restart the notebook kernel and re-open the file to clear Pylance/VSCode diagnostics.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c9fea8",
   "metadata": {},
   "source": [
    "## Instrukcja uruchomienia (po polsku)\n",
    "\n",
    "1. Uruchom komórkę instalacyjną (jeśli jeszcze nie została uruchomiona). Usuwa ona brakujące pakiety (`requests`, `beautifulsoup4`, `python-dateutil`) w interpreterze, na którym działa notebook.\n",
    "2. Po zakończeniu instalacji zrestartuj kernel (Restart Kernel) w górnym menu notebooka.\n",
    "3. Uruchom komórkę z testem (znajduje się poniżej) — powinna pobrać stronę wyników i wypisać liczbę znalezionych linków oraz kilka przykładów.\n",
    "4. Jeśli test zwróci linki — skrypt jest gotowy. Jeśli test zgłosi błąd (np. timeout lub brak połączenia), sprawdź połączenie sieciowe i nagłówki User-Agent.\n",
    "\n",
    "Uwaga: VS Code/Pylance może nadal pokazywać błędy importu przed restartem kernela/interpretera — po instalacji przeładuj okno (Developer: Reload Window) lub wybierz odpowiedni interpreter (Ctrl+Shift+P → Python: Select Interpreter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ca45ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pobieram: https://www.otomoto.pl/osobowe/volkswagen/passat/seg-sedan?search%5Bfilter_enum_fuel_type%5D=diesel&search%5Bfilter_enum_generation%5D=gen-b5-fl-2000-2005&search%5Badvanced_search_expanded%5D=true\n",
      "Znaleziono 13 linków. Przykłady:\n",
      " - https://www.otomoto.pl/osobowe/oferta/volkswagen-passat-ID6HJ8X0.html\n",
      " - https://www.otomoto.pl/osobowe/oferta/volkswagen-passat-ID6HGQO5.html\n",
      " - https://www.otomoto.pl/osobowe/oferta/volkswagen-passat-ID6HKcpM.html\n",
      " - https://www.otomoto.pl/osobowe/oferta/volkswagen-passat-ID6HHYEf.html\n",
      " - https://www.otomoto.pl/osobowe/oferta/volkswagen-passat-ID6HHbyT.html\n",
      " - https://www.otomoto.pl/osobowe/oferta/volkswagen-passat-ID6HIXFg.html\n",
      " - https://www.otomoto.pl/osobowe/oferta/volkswagen-passat-ID6HIf88.html\n",
      " - https://www.otomoto.pl/osobowe/oferta/volkswagen-passat-ID6HKyg5.html\n",
      " - https://www.otomoto.pl/osobowe/oferta/volkswagen-passat-ID6HHJCR.html\n",
      " - https://www.otomoto.pl/osobowe/oferta/volkswagen-passat-ID6HIcwr.html\n",
      "Znaleziono 13 linków. Przykłady:\n",
      " - https://www.otomoto.pl/osobowe/oferta/volkswagen-passat-ID6HJ8X0.html\n",
      " - https://www.otomoto.pl/osobowe/oferta/volkswagen-passat-ID6HGQO5.html\n",
      " - https://www.otomoto.pl/osobowe/oferta/volkswagen-passat-ID6HKcpM.html\n",
      " - https://www.otomoto.pl/osobowe/oferta/volkswagen-passat-ID6HHYEf.html\n",
      " - https://www.otomoto.pl/osobowe/oferta/volkswagen-passat-ID6HHbyT.html\n",
      " - https://www.otomoto.pl/osobowe/oferta/volkswagen-passat-ID6HIXFg.html\n",
      " - https://www.otomoto.pl/osobowe/oferta/volkswagen-passat-ID6HIf88.html\n",
      " - https://www.otomoto.pl/osobowe/oferta/volkswagen-passat-ID6HKyg5.html\n",
      " - https://www.otomoto.pl/osobowe/oferta/volkswagen-passat-ID6HHJCR.html\n",
      " - https://www.otomoto.pl/osobowe/oferta/volkswagen-passat-ID6HIcwr.html\n"
     ]
    }
   ],
   "source": [
    "# Test ekstrakcji linków — uruchom po zainstalowaniu pakietów i restarcie kernela\n",
    "import requests, re\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def listing_links_from_results(html, base_url):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    hrefs = [a.get(\"href\") for a in soup.find_all(\"a\", href=True)]\n",
    "    abs_hrefs = [urljoin(base_url, h) for h in hrefs if h]\n",
    "    patterns = [\n",
    "        re.compile(r\"https?://[^/]*otomoto\\.pl/.+?/oferta/.+?ID[A-Za-z0-9]+\\.html\"),\n",
    "        re.compile(r\"/oferta/\"),\n",
    "    ]\n",
    "    matches = []\n",
    "    for h in abs_hrefs:\n",
    "        for p in patterns:\n",
    "            try:\n",
    "                if p.search(h):\n",
    "                    matches.append(h)\n",
    "                    break\n",
    "            except Exception:\n",
    "                continue\n",
    "    # deduplikuj\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for u in matches:\n",
    "        if u not in seen:\n",
    "            seen.add(u)\n",
    "            result.append(u)\n",
    "    return result\n",
    "\n",
    "search = \"https://www.otomoto.pl/osobowe/volkswagen/passat/seg-sedan?search%5Bfilter_enum_fuel_type%5D=diesel&search%5Bfilter_enum_generation%5D=gen-b5-fl-2000-2005&search%5Badvanced_search_expanded%5D=true\"\n",
    "\n",
    "try:\n",
    "    print(\"Pobieram:\", search)\n",
    "    resp = requests.get(search, headers={\"User-Agent\": \"Mozilla/5.0\"}, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "    links = listing_links_from_results(resp.text, search)\n",
    "    print(f\"Znaleziono {len(links)} linków. Przykłady:\")\n",
    "    for l in links[:10]:\n",
    "        print(\" -\", l)\n",
    "except Exception as e:\n",
    "    print(\"Błąd testu:\", e)\n",
    "    # pomocna wskazówka: uruchom z debug=True w funkcji scrape_search, aby zapisać HTML do pliku i przeanalizować selektory\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
